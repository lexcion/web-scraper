{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import StaleElementReferenceException, TimeoutException, WebDriverException\n",
    "import time\n",
    "import os\n",
    "import threading\n",
    "import keyboard\n",
    "import psutil  # Import psutil to manage system processes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "import pyautogui\n",
    "\n",
    "def select_match(driver, match_id):\n",
    "    # Function to select a specific match\n",
    "    # Implement your logic to select a match based on match_id\n",
    "    pass\n",
    "\n",
    "\n",
    "def scrape_matchinfo(driver):\n",
    "    # Function to scrape match information\n",
    "    match_info = {}\n",
    "    # Implement your scraping logic here\n",
    "    return match_info\n",
    "\n",
    "def scrape_homepage(driver,sport,quarter_type,bet_type,date):\n",
    "    # Function to scrape all text on the homepage\n",
    "    rows_data = []\n",
    "    columns = {\n",
    "        '1': 'match_info',\n",
    "        '2': 'score',\n",
    "        '3': 'col_3',\n",
    "        '4': 'col_4'\n",
    "    }\n",
    "    column_titles = {}  # To store the column titles found\n",
    "\n",
    "    try:\n",
    "        # Wait until the page loads and an element we are interested in is present\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.ag-pinned-left-cols-container')))\n",
    "        \n",
    "        # Get the container with all the rows in the pinned left columns\n",
    "        left_container = driver.find_element(By.CSS_SELECTOR, 'div.ag-pinned-left-cols-container')\n",
    "\n",
    "        # Iterate through each row in the pinned left columns\n",
    "        row_index = 0\n",
    "        while True:\n",
    "            if logged_in(driver) == False:\n",
    "                    break\n",
    "            try:\n",
    "                # Locate each row by row index\n",
    "                left_row = left_container.find_element(By.CSS_SELECTOR, f'div[row-index=\"{row_index}\"]')\n",
    "                # Extract the text or any specific data from the row, including column index\n",
    "                row_data = {'row_index': row_index}\n",
    "                cells = left_row.find_elements(By.CSS_SELECTOR, 'div[aria-colindex]')\n",
    "                for cell in cells:\n",
    "                    col_index = cell.get_attribute('aria-colindex')\n",
    "                    column_name = columns.get(col_index, f'col_{col_index}')\n",
    "                    row_data[column_name] = cell.text\n",
    "                rows_data.append(row_data)\n",
    "                row_index += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Left container row parsing ended at index {row_index} with error: {e}\")\n",
    "                break\n",
    "\n",
    "        # Now, get the container with all the rows in the center columns\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.ag-center-cols-container')))\n",
    "        center_container = driver.find_element(By.CSS_SELECTOR, 'div.ag-center-cols-container')\n",
    "\n",
    "        # Iterate through each row in the center columns and merge with existing data\n",
    "        for row in rows_data:\n",
    "            try:\n",
    "                # Locate each row by row index\n",
    "                center_row = center_container.find_element(By.CSS_SELECTOR, f'div[row-index=\"{row[\"row_index\"]}\"]')\n",
    "                # Extract the text or any specific data from the row, including column index\n",
    "                cells = center_row.find_elements(By.CSS_SELECTOR, 'div[aria-colindex]')\n",
    "                for cell in cells:\n",
    "                    col_index = cell.get_attribute('aria-colindex')\n",
    "                    column_name = columns.get(col_index, f'col_{col_index}')\n",
    "                    row[column_name] = cell.text\n",
    "            except Exception as e:\n",
    "                print(f\"Center container row parsing error for row index {row['row_index']}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Get the column titles from the header starting at aria-colindex 5\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.ag-header-row.ag-header-row-column')))\n",
    "        header_rows = driver.find_elements(By.CSS_SELECTOR, 'div.ag-header-row.ag-header-row-column')\n",
    "        \n",
    "        #print(\"Found header rows:\", len(header_rows))  # Debugging line\n",
    "        for header_row in header_rows:\n",
    "            headers = header_row.find_elements(By.CSS_SELECTOR, 'div[aria-colindex]')\n",
    "            for header in headers:\n",
    "                col_index = header.get_attribute('aria-colindex')\n",
    "                if int(col_index) >= 5:\n",
    "                    try:\n",
    "                        # Inspect the header element\n",
    "                        print(f\"Inspecting header with aria-colindex {col_index}: {header.get_attribute('outerHTML')}\")\n",
    "                        title_element = header.find_element(By.CSS_SELECTOR, 'div[title]')\n",
    "                        column_titles[col_index] = title_element.get_attribute('title')\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error finding title for col_index {col_index}: {e}\")\n",
    "                        column_titles[col_index] = f'col_{col_index}'\n",
    "                    # Debug: Print the aria-colindex and the corresponding title\n",
    "                    print(f'aria-colindex: {col_index}, title: {column_titles[col_index]}')\n",
    "\n",
    "        # Rename the columns in the DataFrame\n",
    "        df = pd.DataFrame(rows_data)\n",
    "        df.rename(columns={f'col_{k}': v for k, v in column_titles.items()}, inplace=True)\n",
    "        \n",
    "        # Save the DataFrame to a CSV file\n",
    "        df.to_csv(f'unabated-database/{sport}/{quarter_type}/{bet_type}/pregame/pregame_{sport}_{quarter_type}_{bet_type}_{date}.csv', index=False)\n",
    "        print(f\"Data saved to pregame_{sport}_{quarter_type}_{bet_type}_{date}.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "def print_currentpage(driver):\n",
    "    # Function to scrape the current page into text and print it\n",
    "    try:\n",
    "        while True:\n",
    "            # Wait until the page loads and an element we are interested in is present\n",
    "            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "            \n",
    "            # Get all text content from the body\n",
    "            body_text = driver.find_element(By.TAG_NAME, \"body\").text\n",
    "            \n",
    "            # Print the text content of the current page\n",
    "            print(body_text)\n",
    "            \n",
    "            # Wait for 10 seconds before the next iteration\n",
    "            time.sleep(10)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "def scrape_pregame(driver):\n",
    "    # Function to scrape pregame odds\n",
    "    pregame_odds = {}\n",
    "    # Implement your scraping logic here\n",
    "    return pregame_odds\n",
    "\n",
    "def scrape_live(driver,sport,quarter_type,bet_type,date):\n",
    "    # Function to scrape live odds\n",
    "    all_live_data = []  # To store all parsed DataFrames\n",
    "\n",
    "    try:\n",
    "        # Wait until the page loads and the element we are interested in is present\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.ag-center-cols-container')))\n",
    "        \n",
    "        # Get the container with all the rows in the center columns\n",
    "        center_container = driver.find_element(By.CSS_SELECTOR, 'div.ag-center-cols-container')\n",
    "\n",
    "        row_index = 0\n",
    "        while True:\n",
    "            \n",
    "            try:\n",
    "                # Locate each row by row index\n",
    "                row = center_container.find_element(By.CSS_SELECTOR, f'div[row-index=\"{row_index}\"]')\n",
    "                \n",
    "                col_index = 5\n",
    "                while True:\n",
    "                    try:\n",
    "                        # Locate each cell by col index\n",
    "                        cell = row.find_element(By.CSS_SELECTOR, f'div[aria-colindex=\"{col_index}\"]')\n",
    "                        react_container = cell.find_element(By.CSS_SELECTOR, 'div.ag-react-container')\n",
    "                        \n",
    "                        # Hover over and click the cell\n",
    "                        ActionChains(driver).move_to_element(react_container).click().perform()\n",
    "                        \n",
    "                        # Wait for the textbox to appear and parse the data\n",
    "                        time.sleep(0.5)  # Adjust sleep time as needed\n",
    "                        df = parse_live_lines(driver,col_index,row_index)\n",
    "                        all_live_data.append(df)\n",
    "                        \n",
    "                        col_index += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"End of columns for row index {row_index} with error: {e}\")\n",
    "                        break\n",
    "                \n",
    "                row_index += 1\n",
    "            except Exception as e:\n",
    "                print(f\"End of rows reached with error: {e}\")\n",
    "                break\n",
    "\n",
    "        # Concatenate all DataFrames\n",
    "        final_df = pd.concat(all_live_data, ignore_index=True)\n",
    "        \n",
    "        # Save the final DataFrame to a CSV file\n",
    "        final_df.to_csv(f'unabated-database/{sport}/{quarter_type}/{bet_type}/live/live_{sport}_{quarter_type}_{bet_type}_{date}.csv', index=False)\n",
    "        print(f\"Live lines data saved to live_{sport}_{quarter_type}_{bet_type}_{date}.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while scraping live odds: {e}\")\n",
    "\n",
    "def parse_live_lines(driver, maincol, mainrow):\n",
    "    \n",
    "    # Disable PyAutoGUI fail-safe feature\n",
    "    pyautogui.FAILSAFE = False\n",
    "\n",
    "    # Function to parse the live lines data\n",
    "    live_data = []\n",
    "    read_rows = set()  # To keep track of row indexes that have been read\n",
    "    try:\n",
    "        # Wait until the element we are interested in is present\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.jsx-619290666')))\n",
    "        \n",
    "        # Get the container with the class jsx-619290666\n",
    "        try:\n",
    "            jsx_container = driver.find_element(By.CSS_SELECTOR, 'div.jsx-619290666')\n",
    "            print(\"Found jsx_container\")\n",
    "        except Exception as e:\n",
    "            print(f\"Data container not found: {e}\")\n",
    "            return pd.DataFrame()  # Return an empty DataFrame if the container is not found\n",
    "        \n",
    "        # Click the button with id=\"buttonGameStatusLive\"\n",
    "        try:\n",
    "            live_button = jsx_container.find_element(By.ID, 'buttonGameStatusLive')\n",
    "            live_button.click()\n",
    "            print(\"Clicked live_button\")\n",
    "            time.sleep(1)  # Wait for the data to load\n",
    "        except Exception as e:\n",
    "            print(f\"Live button not found or not clickable: {e}\")\n",
    "            return pd.DataFrame()  # Return an empty DataFrame if the button is not found or not clickable\n",
    "\n",
    "        # Wait until the element we are interested in is present\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.ag-center-cols-container')))\n",
    "        \n",
    "        # Get the container with all the rows in the center columns\n",
    "        center_container = jsx_container.find_element(By.CSS_SELECTOR, 'div.ag-center-cols-container')\n",
    "        print(\"Found center_container\")\n",
    "\n",
    "        tries = 0\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                # Locate all rows in the center container\n",
    "                rows = center_container.find_elements(By.CSS_SELECTOR, 'div[role=\"row\"]')\n",
    "                for row in rows:\n",
    "                    row_index = int(row.get_attribute('row-index'))\n",
    "                    if row_index not in read_rows:  # Only process rows that haven't been read\n",
    "                        try:\n",
    "                            # Extract the data for each column\n",
    "                            time_text = row.find_element(By.CSS_SELECTOR, 'div[aria-colindex=\"1\"]').text\n",
    "                            away_text = row.find_element(By.CSS_SELECTOR, 'div[aria-colindex=\"2\"]').text\n",
    "                            home_text = row.find_element(By.CSS_SELECTOR, 'div[aria-colindex=\"3\"]').text\n",
    "                            available = \"Closed\" if \"line-through\" in\\\n",
    "                                row.find_element(By.CSS_SELECTOR, 'div[aria-colindex=\"2\"]').find_element(By.CSS_SELECTOR, 'span.pr-2').get_attribute(\"style\") else \"Open\"\n",
    "                            \n",
    "                            \n",
    "                            live_data.append({\n",
    "                                \"Time\": time_text,\n",
    "                                \"Away\": away_text,\n",
    "                                \"Home\": home_text,\n",
    "                                \"Available\": available,\n",
    "                                \"Row\": f\"row_{mainrow}\",\n",
    "                                \"Column\": f\"col_{maincol}\"\n",
    "                            })\n",
    "                            #print(f\"Parsed row {row_index}: Time={time_text}, Away={away_text}, Home={home_text}, Available={available}, Column=col_{maincol}\")\n",
    "                            read_rows.add(row_index)  # Mark this row as read\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error parsing row {row_index}: {e}\")\n",
    "                            continue\n",
    "                \n",
    "                # Click at the bottom-right to load more rows\n",
    "                #window_size = driver.get_window_size()\n",
    "                pyautogui.click()\n",
    "                print(\"Clicked at the bottom-right corner to load more rows\")\n",
    "                time.sleep(0.5)\n",
    "\n",
    "                # Check if new rows have been loaded\n",
    "                hasnewrow = False\n",
    "                new_rows = center_container.find_elements(By.CSS_SELECTOR, 'div[role=\"row\"]')\n",
    "                for row in new_rows:\n",
    "                    row_index = int(row.get_attribute('row-index'))\n",
    "                    if row_index not in read_rows:\n",
    "                        hasnewrow = True\n",
    "                        \n",
    "                tries += 1\n",
    "                \n",
    "                if (hasnewrow==False and tries > 0):\n",
    "                    print(\"No new rows loaded, finishing up\")\n",
    "                    break  # Exit if no new rows were loaded\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Scroll bar click failed with error: {e}\")\n",
    "                break\n",
    "\n",
    "        # Click the button with class=\"close\" to close the data table\n",
    "        try:\n",
    "            close_button = driver.find_element(By.CSS_SELECTOR, 'button.close')\n",
    "            close_button.click()\n",
    "            print(\"Clicked close_button\")\n",
    "        except Exception as e:\n",
    "            print(f\"Close button not found or not clickable: {e}\")\n",
    "\n",
    "        # Convert the list of dictionaries to a DataFrame\n",
    "        df = pd.DataFrame(live_data)\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while parsing live lines: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def merge_info(live_path='live.csv', pregame_path='pregame.csv', output_path='merged.csv'):\n",
    "    print('MERGEINFO')\n",
    "    try:\n",
    "        # Check if the input files exist and are not empty\n",
    "        if os.stat(live_path).st_size == 0 or os.stat(pregame_path).st_size == 0:\n",
    "            raise ValueError(\"One of the input files is empty.\")\n",
    "\n",
    "        # Load the live_lines.csv and nba_matches.csv files into DataFrames\n",
    "        live_df = pd.read_csv(live_path)\n",
    "        pregame_df = pd.read_csv(pregame_path)\n",
    "\n",
    "        # Strip whitespace from column names in nba_matches_df\n",
    "        pregame_df.columns = pregame_df.columns.str.strip()\n",
    "\n",
    "        # Remove double spaces and leading/trailing spaces from every cell in nba_matches_df\n",
    "        pregame_df = pregame_df.applymap(lambda x: ' '.join(x.split()) if isinstance(x, str) else x)\n",
    "\n",
    "        #print(pregame_df.columns)  # For debugging, print the cleaned column names\n",
    "        #print(live_df.columns)  # For debugging, print the cleaned column names\n",
    "\n",
    "        # Initialize new columns in live_lines_df for match_info and score\n",
    "        live_df['match_info'] = ''\n",
    "        live_df['score'] = ''\n",
    "        live_df['pregame'] = ''\n",
    "        live_df['book'] = ''\n",
    "\n",
    "        # Iterate through each row in live_lines_df\n",
    "        for index, row in live_df.iterrows():\n",
    "            try:\n",
    "                # Extract row and column info from live_lines_df\n",
    "                row_str = row['Row']\n",
    "                col_str = row['Column']\n",
    "\n",
    "                # Extract the row_index and col_index\n",
    "                row_index = int(row_str.split('_')[1])\n",
    "                col_index = int(col_str.split('_')[1])\n",
    "\n",
    "                # Find the corresponding row in nba_matches_df\n",
    "                match_info = pregame_df.loc[pregame_df['row_index'] == row_index, 'match_info'].values[0]\n",
    "                score = pregame_df.loc[pregame_df['row_index'] == row_index, 'score'].values[0]\n",
    "\n",
    "                # Find the corresponding column (e.g., col_5 -> the correct bookmaker)\n",
    "                col_name = pregame_df.columns[col_index]\n",
    "                pregame = pregame_df.loc[pregame_df['row_index'] == row_index, col_name].values[0]\n",
    "                book = pregame_df.columns[col_index]\n",
    "\n",
    "                # Update the live_lines_df with the matched info\n",
    "                live_df.at[index, 'match_info'] = match_info\n",
    "                live_df.at[index, 'score'] = score\n",
    "                live_df.at[index, 'pregame'] = pregame\n",
    "                live_df.at[index, 'book'] = book\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row {index}: {e}\")\n",
    "                raise\n",
    "\n",
    "        # Apply cleaning to live_lines_df as well to remove excess spaces\n",
    "        live_df = live_df.applymap(lambda x: ' '.join(x.split()) if isinstance(x, str) else x)\n",
    "\n",
    "        # Save the updated DataFrame to a new CSV file\n",
    "        live_df.to_csv(output_path, index=False)\n",
    "        print(f\"Merged data saved to {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}. Saving an empty output CSV.\")\n",
    "        \n",
    "        # Define the columns that would have been in the merged CSV\n",
    "        columns = ['match_info', 'score', 'pregame', 'book', 'Time', 'Away', 'Home', 'Available', 'Row', 'Column']\n",
    "        \n",
    "        # Create an empty DataFrame with these columns\n",
    "        empty_df = pd.DataFrame(columns=columns)\n",
    "        \n",
    "        # Save the empty DataFrame to the output path\n",
    "        empty_df.to_csv(output_path, index=False)\n",
    "        print(f\"Empty merged data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import StaleElementReferenceException, TimeoutException, WebDriverException\n",
    "import time\n",
    "import os\n",
    "import threading\n",
    "import keyboard  # Import the keyboard module for global key listening\n",
    "\n",
    "# Global variable to control the pause state\n",
    "pause_flag = False\n",
    "\n",
    "def change_date(driver, day):\n",
    "    try:\n",
    "        print(f\"Attempting to change date to: {day}\")\n",
    "        date_picker = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.CLASS_NAME, 'react-datepicker__input-container'))\n",
    "        )\n",
    "        date_picker.click()\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.visibility_of_element_located((By.CLASS_NAME, 'react-datepicker'))\n",
    "        )\n",
    "        day_element = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, f\"//div[contains(@class, 'react-datepicker__day') and text()='{day}' and not(contains(@class, 'react-datepicker__day--outside-month')) and not(@aria-disabled='true')]\"))\n",
    "        )\n",
    "        day_element.click()\n",
    "        print(f\"Successfully changed date to: {day}\")\n",
    "        return True\n",
    "    except TimeoutException:\n",
    "        print(f\"TimeoutException: Failed to find or click the date {day}.\")\n",
    "    except StaleElementReferenceException:\n",
    "        print(f\"StaleElementReferenceException: The page structure might have changed for date {day}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while changing the date to {day}: {e}\")\n",
    "    return False\n",
    "\n",
    "def go_to_next_month(driver):\n",
    "    try:\n",
    "        date_picker = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.CLASS_NAME, 'react-datepicker__input-container'))\n",
    "        )\n",
    "        date_picker.click()\n",
    "        next_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.react-datepicker__navigation--next\"))\n",
    "        )\n",
    "        next_button.click()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error clicking next month: {e}\")\n",
    "    return False\n",
    "\n",
    "def go_to_prev_month(driver):\n",
    "    try:\n",
    "        date_picker = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.CLASS_NAME, 'react-datepicker__input-container'))\n",
    "        )\n",
    "        date_picker.click()\n",
    "        print(\"Going to the previous month...\")\n",
    "        prev_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.react-datepicker__navigation--previous\"))\n",
    "        )\n",
    "        prev_button.click()\n",
    "        print(\"Moved to the previous month.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error clicking previous month: {e}\")\n",
    "    return False\n",
    "\n",
    "def get_available_days(driver):\n",
    "    try:\n",
    "        date_picker = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.CLASS_NAME, 'react-datepicker__input-container'))\n",
    "        )\n",
    "        date_picker.click()\n",
    "        available_days_elements = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, \"//div[contains(@class, 'react-datepicker__day') and not(contains(@class, 'react-datepicker__day--outside-month')) and not(@aria-disabled='true')]\"))\n",
    "        )\n",
    "        available_days = [day.text.strip() for day in available_days_elements if day.text.strip().isdigit()]\n",
    "        print(f\"Found {len(available_days)} available days to scan: {available_days}\")\n",
    "        date_picker.click()  # Close the date picker after fetching the days\n",
    "        return available_days\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching available days: {e}\")\n",
    "        return []\n",
    "\n",
    "def login(driver, email, password):\n",
    "    try:\n",
    "        email_input = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"c19ad00c3.c30d9afca\"))\n",
    "        )\n",
    "        email_input.send_keys(email)\n",
    "        password_input = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"c19ad00c3.ce9b3173b\"))\n",
    "        )\n",
    "        password_input.send_keys(password)\n",
    "        login_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.CLASS_NAME, \"cc199ae96\"))\n",
    "        )\n",
    "        login_button.click()\n",
    "        print(\"Login successful.\")\n",
    "        return True\n",
    "    except TimeoutException:\n",
    "        print(\"TimeoutException: Failed to locate login elements.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during login: {e}\")\n",
    "    return False\n",
    "\n",
    "def select_market(driver, bet_type):\n",
    "    try:\n",
    "        bet_type_to_title = {\n",
    "            \"ml\": \"Moneyline\",\n",
    "            \"spread\": \"Spread\",\n",
    "            \"total\": \"Total\",\n",
    "            \"combined\": \"Combined\"\n",
    "        }\n",
    "        button_title = bet_type_to_title.get(bet_type.lower())\n",
    "        if not button_title:\n",
    "            raise ValueError(f\"Invalid bet_type: {bet_type}. Must be 'ml', 'spread', 'total', or 'combined'.\")\n",
    "        print(\"Locating the second occurrence of the dropdown button...\")\n",
    "        dropdown_buttons = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, \"btn-sm.btn-falcon-primary.dropdown-toggle.btn.btn-secondary\"))\n",
    "        )\n",
    "        if len(dropdown_buttons) < 2:\n",
    "            raise Exception(\"Unable to find the second dropdown button.\")\n",
    "        dropdown_button = dropdown_buttons[1]  # Get the second occurrence\n",
    "        dropdown_button.click()\n",
    "        print(\"Clicked the second dropdown button.\")\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.visibility_of_element_located((By.CLASS_NAME, 'dropdown-menu.show'))\n",
    "        )\n",
    "        print(f\"Selecting the market with title '{button_title}'...\")\n",
    "        market_option = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, f\"//button[text()='{button_title}' and @role='menuitem']\"))\n",
    "        )\n",
    "        market_option.click()\n",
    "        print(f\"Selected market: {button_title}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error selecting market: {e}\")\n",
    "    return False\n",
    "\n",
    "def initialize_scraper():\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    driver = uc.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "def pause_listener():\n",
    "    global pause_flag\n",
    "    # Use the keyboard module to listen globally for the 'p' key press\n",
    "    while True:\n",
    "        keyboard.wait('p')\n",
    "        pause_flag = not pause_flag\n",
    "        if pause_flag:\n",
    "            print(\"Scraping paused. Press 'p' again to resume.\")\n",
    "        else:\n",
    "            print(\"Scraping resumed.\")\n",
    "            \n",
    "def logged_in(driver):\n",
    "    try:\n",
    "        # Check if the avatar element is present, indicating that the user is logged in\n",
    "        WebDriverWait(driver, 0.5).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, 'avatar.avatar-xl'))\n",
    "        )\n",
    "        print(\"User is logged in.\")\n",
    "        return True\n",
    "    except TimeoutException:\n",
    "        print(\"User is not logged in.\")\n",
    "        return False\n",
    "\n",
    "def clear_cache_cookies(driver):\n",
    "    \"\"\"Clears the browser cache and cookies.\"\"\"\n",
    "    try:\n",
    "        driver.delete_all_cookies()  # Clears all cookies\n",
    "        driver.execute_cdp_cmd('Network.clearBrowserCache', {})  # Clears the cache\n",
    "        print(\"Cache and cookies cleared.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error clearing cache and cookies: {e}\")\n",
    "        \n",
    "def kill_chrome_processes():\n",
    "    \"\"\"Kill any lingering Chrome or ChromeDriver processes.\"\"\"\n",
    "    for proc in psutil.process_iter():\n",
    "        # Check if process name contains 'chrome' or 'chromedriver'\n",
    "        if 'chrome' in proc.name().lower() or 'chromedriver' in proc.name().lower():\n",
    "            try:\n",
    "                proc.kill()\n",
    "                print(f\"Killed process {proc.name()} with PID {proc.pid}\")\n",
    "            except psutil.NoSuchProcess:\n",
    "                print(f\"Process {proc.name()} with PID {proc.pid} already terminated.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error killing process {proc.name()}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt detected. Exiting the program...\n",
      "Killed process chrome.exe with PID 9832\n",
      "Killed process chrome.exe with PID 11780\n",
      "Killed process chrome.exe with PID 15632\n",
      "Killed process chrome.exe with PID 20996\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    global pause_flag\n",
    "\n",
    "    sport = \"nba\"\n",
    "    bet_type = \"ml\"\n",
    "    quarter_type = \"q4\"\n",
    "    email = \"chunkmonkey1303@gmail.com\"\n",
    "    password = \"Chunkmonkey1303!\"\n",
    "    total_days_to_scan = 10000\n",
    "    scanned_days = 0\n",
    "    months_scan = 5\n",
    "    month_position = 0\n",
    "\n",
    "    threading.Thread(target=pause_listener, daemon=True).start()\n",
    "\n",
    "    try:\n",
    "        while months_scan - month_position >= 0 and scanned_days < total_days_to_scan:\n",
    "            driver = initialize_scraper()\n",
    "            driver.maximize_window()\n",
    "\n",
    "            try:\n",
    "                driver.get(\"https://unabated.com/api/auth/login?returnTo=/nba/odds\")\n",
    "                time.sleep(1)\n",
    "\n",
    "                login(driver, email, password)\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, 'react-datepicker__input-container'))\n",
    "                )\n",
    "\n",
    "                select_market(driver, bet_type)\n",
    "                time.sleep(1)\n",
    "\n",
    "                for _ in range(months_scan - month_position):\n",
    "                    go_to_prev_month(driver)\n",
    "                    time.sleep(0.2)\n",
    "\n",
    "                while scanned_days < total_days_to_scan:\n",
    "                    try:\n",
    "                        while pause_flag:\n",
    "                            time.sleep(1)\n",
    "\n",
    "                        if not logged_in(driver):\n",
    "                            driver.quit()\n",
    "                            break\n",
    "\n",
    "                        print(f\"Scanning for available days in month {month_position}...\")\n",
    "\n",
    "                        date_picker_input = WebDriverWait(driver, 10).until(\n",
    "                            EC.presence_of_element_located((By.CSS_SELECTOR, 'input.datepicker.form-control.datepicker-container'))\n",
    "                        )\n",
    "                        current_date = date_picker_input.get_attribute('value')\n",
    "                        current_month = current_date.split('/')[0]\n",
    "                        date = current_date.replace(\"/\", \"-\")\n",
    "                        print(f\"Current month: {current_month}\")\n",
    "\n",
    "                        available_days = get_available_days(driver)\n",
    "\n",
    "                        for day in available_days:\n",
    "                            if not logged_in(driver):\n",
    "                                break\n",
    "\n",
    "                            if scanned_days >= total_days_to_scan:\n",
    "                                break\n",
    "\n",
    "                            try:\n",
    "                                while pause_flag:\n",
    "                                    time.sleep(1)\n",
    "\n",
    "                                print(f\"Processing day: {day}\")\n",
    "                                change_date(driver, day)\n",
    "\n",
    "                                current_date = driver.find_element(By.CSS_SELECTOR, 'input.datepicker.form-control.datepicker-container').get_attribute('value')\n",
    "                                date = current_date.replace(\"/\", \"-\")\n",
    "\n",
    "                                merged_csv_path = f'unabated-database/{sport}/{quarter_type}/{bet_type}/merged/merged_{sport}_{quarter_type}_{bet_type}_{date}.csv'\n",
    "\n",
    "                                if os.path.exists(merged_csv_path) and os.path.getsize(merged_csv_path) > 50 * 1024:\n",
    "                                    print(f\"Skipping day {day} because {merged_csv_path} is already processed and larger than 50 KB.\")\n",
    "                                    continue\n",
    "\n",
    "                                scrape_homepage(driver, sport, quarter_type, bet_type, date)\n",
    "\n",
    "                                if not logged_in(driver):\n",
    "                                    break\n",
    "\n",
    "                                scrape_live(driver, sport, quarter_type, bet_type, date)\n",
    "\n",
    "                                if not logged_in(driver):\n",
    "                                    break\n",
    "\n",
    "                                merge_info(\n",
    "                                    live_path=f'unabated-database/{sport}/{quarter_type}/{bet_type}/live/live_{sport}_{quarter_type}_{bet_type}_{date}.csv',\n",
    "                                    pregame_path=f'unabated-database/{sport}/{quarter_type}/{bet_type}/pregame/pregame_{sport}_{quarter_type}_{bet_type}_{date}.csv',\n",
    "                                    output_path=f'unabated-database/{sport}/{quarter_type}/{bet_type}/merged/merged_{sport}_{quarter_type}_{bet_type}_{date}.csv'\n",
    "                                )\n",
    "\n",
    "                                scanned_days += 1\n",
    "\n",
    "                            except StaleElementReferenceException as e:\n",
    "                                print(f\"StaleElementReferenceException encountered. Retrying...\")\n",
    "                                time.sleep(1)\n",
    "\n",
    "                        if scanned_days < total_days_to_scan:\n",
    "                            go_to_next_month(driver)\n",
    "                            month_position += 1\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Exception detected: {e}.\")\n",
    "                        break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Crash Detected. Restarting: {e}.\")\n",
    "                continue\n",
    "\n",
    "            finally:\n",
    "                driver.quit()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"KeyboardInterrupt detected. Exiting the program...\")\n",
    "\n",
    "    finally:\n",
    "        kill_chrome_processes()  # Ensure all Chrome processes are terminated when exiting\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
